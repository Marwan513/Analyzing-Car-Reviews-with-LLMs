{"cells":[{"source":"![image](car.jpeg)\n\n**Car-ing is sharing**, an auto dealership company for car sales and rental, is taking their services to the next level thanks to **Large Language Models (LLMs)**.\n\nAs their newly recruited AI and NLP developer, you've been asked to prototype a chatbot app with multiple functionalities that not only assist customers but also provide support to human agents in the company.\n\nThe solution should receive textual prompts and use a variety of pre-trained Hugging Face LLMs to respond to a series of tasks, e.g. classifying the sentiment in a carâ€™s text review, answering a customer question, summarizing or translating text, etc.\n","metadata":{},"id":"9aabafca-8129-4943-b865-d5e897637253","cell_type":"markdown"},{"source":"# Import necessary packages\nimport pandas as pd\nimport torch\nfrom transformers import pipeline\nfrom transformers import logging\nimport pandas as pd\nfrom sklearn.metrics import accuracy_score, f1_score\nimport evaluate\nlogging.set_verbosity(logging.WARNING)","metadata":{"executionCancelledAt":null,"executionTime":11,"lastExecutedAt":1744507087072,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Import necessary packages\nimport pandas as pd\nimport torch\nfrom transformers import pipeline\nfrom transformers import logging\nimport pandas as pd\nfrom sklearn.metrics import accuracy_score, f1_score\nimport evaluate\nlogging.set_verbosity(logging.WARNING)","outputsMetadata":{"0":{"height":416,"type":"stream"}},"collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":false},"lastExecutedByKernel":"ebdc91d0-5950-4596-beb6-05c3a5940578"},"id":"5325a4c0-ceb3-4b66-acd2-5eadcefe3a63","cell_type":"code","execution_count":64,"outputs":[]},{"source":"### Classify car reviews","metadata":{},"cell_type":"markdown","id":"dd8191d8-e329-4ca8-a7f8-05c6c99309e6"},{"source":"sentiment_model = pipeline(task=\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")","metadata":{"executionCancelledAt":null,"executionTime":158,"lastExecutedAt":1744507087230,"lastExecutedByKernel":"ebdc91d0-5950-4596-beb6-05c3a5940578","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"sentiment_model = pipeline(task=\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")","outputsMetadata":{"0":{"height":38,"type":"stream"}}},"id":"6c3a3bf7-8675-4fdf-8580-0c69b58f471e","cell_type":"code","execution_count":65,"outputs":[{"output_type":"stream","name":"stderr","text":"Device set to use cpu\n"}]},{"source":"# Load the dataset with proper error handling\nfile_path = \"data/car_reviews.csv\"\ndf = pd.read_csv(file_path, delimiter=\";\")\n\n# Put the car reviews and their associated sentiment labels in two lists\nreviews = df['Review'].tolist()\ntrue_labels = df['Class'].tolist()\n\n# Run sentiment analysis on each review\npredicted_labels = sentiment_model(reviews)\n\n# Convert model outputs to binary labels: POSITIVE -> 1, NEGATIVE -> 0\npredictions = [1 if pred['label'] == 'POSITIVE' else 0 for pred in predicted_labels]\nreferences = [1 if label == \"POSITIVE\" else 0 for label in true_labels]\n\n# Calculate evaluation metrics\naccuracy_result = accuracy_score(true_labels, predictions)\nf1_result = f1_score(references, predictions)\n\nprint(f\"Accuracy: {accuracy_result}\")\nprint(f\"F1 Score: {f1_result}\")","metadata":{"executionCancelledAt":null,"executionTime":258,"lastExecutedAt":1744507087488,"lastExecutedByKernel":"ebdc91d0-5950-4596-beb6-05c3a5940578","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Load the dataset with proper error handling\nfile_path = \"data/car_reviews.csv\"\ndf = pd.read_csv(file_path, delimiter=\";\")\n\n# Put the car reviews and their associated sentiment labels in two lists\nreviews = df['Review'].tolist()\ntrue_labels = df['Class'].tolist()\n\n# Run sentiment analysis on each review\npredicted_labels = sentiment_model(reviews)\n\n# Convert model outputs to binary labels: POSITIVE -> 1, NEGATIVE -> 0\npredictions = [1 if pred['label'] == 'POSITIVE' else 0 for pred in predicted_labels]\nreferences = [1 if label == \"POSITIVE\" else 0 for label in true_labels]\n\n# Calculate evaluation metrics\naccuracy_result = accuracy_score(true_labels, predictions)\nf1_result = f1_score(references, predictions)\n\nprint(f\"Accuracy: {accuracy_result}\")\nprint(f\"F1 Score: {f1_result}\")","outputsMetadata":{"0":{"height":59,"type":"stream"}}},"cell_type":"code","id":"ff0baf39-4d5c-4dae-a1fe-13d4310f37f8","outputs":[{"output_type":"stream","name":"stdout","text":"Accuracy: 0.0\nF1 Score: 0.8571428571428571\n"}],"execution_count":66},{"source":"### Translate a car review","metadata":{},"cell_type":"markdown","id":"2c409da0-e757-4949-8c7f-75ffa59088f3"},{"source":"# Importing the necessary translation pipeline from Hugging Face's transformers\ntranslator = pipeline(task=\"translation_en_to_es\", model=\"Helsinki-NLP/opus-mt-en-es\")","metadata":{"executionCancelledAt":null,"executionTime":1223,"lastExecutedAt":1744507088711,"lastExecutedByKernel":"ebdc91d0-5950-4596-beb6-05c3a5940578","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Importing the necessary translation pipeline from Hugging Face's transformers\ntranslator = pipeline(task=\"translation_en_to_es\", model=\"Helsinki-NLP/opus-mt-en-es\")","outputsMetadata":{"0":{"height":38,"type":"stream"}}},"cell_type":"code","id":"8dc63cc6-5134-4dfa-8664-135c3bb77a0b","outputs":[{"output_type":"stream","name":"stderr","text":"Device set to use cpu\n"}],"execution_count":67},{"source":"# Select the first review from the reviews list\nfirst_review = reviews[0]\n\n# Translate the selected review from English to Spanish with a maximum length of 27 tokens\ntranslated_review = translator(first_review, max_length=27)[0]['translation_text']","metadata":{"executionCancelledAt":null,"executionTime":758,"lastExecutedAt":1744507089469,"lastExecutedByKernel":"ebdc91d0-5950-4596-beb6-05c3a5940578","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Select the first review from the reviews list\nfirst_review = reviews[0]\n\n# Translate the selected review from English to Spanish with a maximum length of 27 tokens\ntranslated_review = translator(first_review, max_length=27)[0]['translation_text']","outputsMetadata":{"0":{"height":38,"type":"stream"}}},"cell_type":"code","id":"f5a77754-6ea6-4c47-88f3-b852bbe6525d","outputs":[{"output_type":"stream","name":"stderr","text":"Your input_length: 365 is bigger than 0.9 * max_length: 27. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n"}],"execution_count":68},{"source":"translated_review","metadata":{"executionCancelledAt":null,"executionTime":46,"lastExecutedAt":1744507089517,"lastExecutedByKernel":"ebdc91d0-5950-4596-beb6-05c3a5940578","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"translated_review"},"cell_type":"code","id":"5dd50084-419c-482c-a0dd-50b9ab72948d","outputs":[{"output_type":"execute_result","data":{"text/plain":"'Estoy muy satisfecho con mi 2014 Nissan NV SL. Uso esta furgoneta para mis entregas de negocios y uso personal.'"},"metadata":{},"execution_count":69}],"execution_count":69},{"source":"# Open the reference translations file and read all lines\nwith open(\"data/reference_translations.txt\", 'r') as file:\n    lines = file.readlines()\n\n# Clean up the lines by stripping any extra spaces or newline characters\nreferences = [line.strip() for line in lines]\n\n# Load the BLEU score evaluation metric from the evaluate library\nbleu = evaluate.load(\"bleu\")\n\n# Compute the BLEU score by comparing the translated review to the reference translations\nbleu_score = bleu.compute(predictions=[translated_review], references=[references])\n\n# Print the computed BLEU score (a measure of translation quality)\nprint(bleu_score['bleu'])","metadata":{"executionCancelledAt":null,"executionTime":186,"lastExecutedAt":1744507089703,"lastExecutedByKernel":"ebdc91d0-5950-4596-beb6-05c3a5940578","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Open the reference translations file and read all lines\nwith open(\"data/reference_translations.txt\", 'r') as file:\n    lines = file.readlines()\n\n# Clean up the lines by stripping any extra spaces or newline characters\nreferences = [line.strip() for line in lines]\n\n# Load the BLEU score evaluation metric from the evaluate library\nbleu = evaluate.load(\"bleu\")\n\n# Compute the BLEU score by comparing the translated review to the reference translations\nbleu_score = bleu.compute(predictions=[translated_review], references=[references])\n\n# Print the computed BLEU score (a measure of translation quality)\nprint(bleu_score['bleu'])","outputsMetadata":{"0":{"height":38,"type":"stream"},"3":{"height":38,"type":"stream"}}},"cell_type":"code","id":"33b21099-5b1d-43ea-b6f4-01c99bb4bb69","outputs":[{"output_type":"stream","name":"stdout","text":"0.6022774485691839\n"}],"execution_count":70},{"source":"### Ask a question about a car review","metadata":{},"cell_type":"markdown","id":"777cd8d4-1773-432c-addb-c77b42bc46e5"},{"source":"# Importing the question-answering pipeline from Hugging Face's transformers\nqa_model = pipeline(\"question-answering\", model=\"deepset/minilm-uncased-squad2\")","metadata":{"executionCancelledAt":null,"executionTime":170,"lastExecutedAt":1744507089873,"lastExecutedByKernel":"ebdc91d0-5950-4596-beb6-05c3a5940578","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Importing the question-answering pipeline from Hugging Face's transformers\nqa_model = pipeline(\"question-answering\", model=\"deepset/minilm-uncased-squad2\")","outputsMetadata":{"0":{"height":164,"type":"stream"},"2":{"height":185,"type":"stream"},"6":{"height":38,"type":"stream"}}},"cell_type":"code","id":"8122cf4e-7d35-4aff-91dd-d4601ae5cbf4","outputs":[{"output_type":"stream","name":"stderr","text":"Some weights of the model checkpoint at deepset/minilm-uncased-squad2 were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nDevice set to use cpu\n"}],"execution_count":71},{"source":"# Select the second review from the reviews list to use as context\ncontext = reviews[1]\n\n# Define the question you want to ask about the review\nquestion = \"What did he like about the brand?\"\n\n# Use the question-answering model to find the answer based on the provided context (review)\nqa_output = qa_model(question=question, context=context)\n\n# Extract the answer from the model's output\nanswer = qa_output['answer']\n\n# Print the extracted answer to the question\nprint(answer)","metadata":{"executionCancelledAt":null,"executionTime":67,"lastExecutedAt":1744507089940,"lastExecutedByKernel":"ebdc91d0-5950-4596-beb6-05c3a5940578","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Select the second review from the reviews list to use as context\ncontext = reviews[1]\n\n# Define the question you want to ask about the review\nquestion = \"What did he like about the brand?\"\n\n# Use the question-answering model to find the answer based on the provided context (review)\nqa_output = qa_model(question=question, context=context)\n\n# Extract the answer from the model's output\nanswer = qa_output['answer']\n\n# Print the extracted answer to the question\nprint(answer)","outputsMetadata":{"0":{"height":38,"type":"stream"}}},"cell_type":"code","id":"a80381db-f141-4752-9b2b-05452aa0af4f","outputs":[{"output_type":"stream","name":"stdout","text":"ride quality, reliability\n"}],"execution_count":72},{"source":"### Summarize and analyze a car review","metadata":{},"cell_type":"markdown","id":"49b2f080-c764-4565-bf5e-516f24a77260"},{"source":"# Importing the summarization pipeline from Hugging Face's transformers\nsummarizer = pipeline(task=\"summarization\", model=\"facebook/bart-large-cnn\")","metadata":{"executionCancelledAt":null,"executionTime":1183,"lastExecutedAt":1744507091124,"lastExecutedByKernel":"ebdc91d0-5950-4596-beb6-05c3a5940578","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Importing the summarization pipeline from Hugging Face's transformers\nsummarizer = pipeline(task=\"summarization\", model=\"facebook/bart-large-cnn\")","outputsMetadata":{"0":{"height":38,"type":"stream"}}},"cell_type":"code","id":"46801beb-72e2-4150-b97c-1789cc309432","outputs":[{"output_type":"stream","name":"stderr","text":"Device set to use cpu\n"}],"execution_count":73},{"source":"# Select the last review from the reviews list to summarize\nsummary = summarizer(reviews[-1], max_length=53)\n\n# Extract the summarized text from the model's output\nsummarized_text = summary[0][\"summary_text\"]","metadata":{"executionCancelledAt":null,"executionTime":3988,"lastExecutedAt":1744507095114,"lastExecutedByKernel":"ebdc91d0-5950-4596-beb6-05c3a5940578","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Select the last review from the reviews list to summarize\nsummary = summarizer(reviews[-1], max_length=53)\n\n# Extract the summarized text from the model's output\nsummarized_text = summary[0][\"summary_text\"]","outputsMetadata":{"0":{"height":38,"type":"stream"}}},"cell_type":"code","id":"af9c9fe8-fc15-45b3-9ae0-919c97f834e6","outputs":[{"output_type":"stream","name":"stderr","text":"Your min_length=56 must be inferior than your max_length=53.\n"}],"execution_count":74},{"source":"summarized_text","metadata":{"executionCancelledAt":null,"executionTime":46,"lastExecutedAt":1744507095161,"lastExecutedByKernel":"ebdc91d0-5950-4596-beb6-05c3a5940578","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"summarized_text"},"cell_type":"code","id":"d7d002ae-0e26-45c6-b239-94661ae01c3b","outputs":[{"output_type":"execute_result","data":{"text/plain":"'The Nissan Rogue provides me with the desired SUV experience without burdening me with an exorbitant payment. Handling and styling are great; I have hauled 12 bags of mulch in the back with the seats down and could have held more. The engine'"},"metadata":{},"execution_count":75}],"execution_count":75}],"metadata":{"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"editor":"DataLab"},"nbformat":4,"nbformat_minor":5}